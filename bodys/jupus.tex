JUPUS is at an inflection point in legal tech—scaling generative AI and agentic capabilities while protecting provenance, reliability, and user trust. That balance is exactly where I’ve focused my work: translating research-grade LLM ideas into dependable features and the standards, evaluations, and tooling that keep them production-ready. I’m particularly drawn to workflows like contract analysis, drafting, and due diligence, where groundedness and citation fidelity are non-negotiable and cross-functional collaboration is essential.

I’ve built agentic systems end to end: my master’s thesis delivers an LLM agent for interactive data analysis (tool use, planning, memory), and I co-authored VotingAid (CEUR 2025), a multi-step assistant guiding complex user decisions. For long-form content, I designed RAG pipelines with hybrid retrieval and evaluators to improve grounding and citations—directly applicable to legal documents. I bring MLOps discipline (CI/CD for LLMs, data/prompt versioning, evaluation/monitoring aligned with CRISP-ML(Q), guardrails, audit trails) and practical delivery experience from KPMG and Deutsche Bahn, plus applied research with a published multi-stage geospatial model (Springer 2023). Recent agent systems I built ran in pilot/limited production with real users, where I owned design through monitoring and communicated trade-offs clearly to stakeholders.

If helpful, I’d start by mapping your AI stack and defining metrics for groundedness, citation quality, latency, and cost (30 days), ship an agentic MVP for contract analysis with verifiable citations and an evaluation harness (60 days), then harden for scale—observability, red-teaming, PII handling, cost controls, and SLAs (90 days). I’m CET-based and ready to take hands-on ownership while learning from your AI Lead and partnering closely with product and engineering.