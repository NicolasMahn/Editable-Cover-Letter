Parloa ist für mich der Maßstab für unternehmensfähige Conversational‑AI: AI Agents, die Anliegen lösen und Beziehungen vertiefen – sicher, verlässlich, messbar. Genau dort arbeite ich: LLM‑Agents, RAG und MLOps mit Fokus auf robuste Dialoge bei hoher Last. Ihr Lifecycle‑Ansatz (Definieren–Testen–Skalieren–Optimieren) entspricht meinem Modus: iterativ, datengetrieben und mit klaren Qualitätszielen.

In Projekten habe ich RAG‑Architekturen mit Guardrails, Tool‑Use und deterministischen Fallbacks für Abrechnung, Adressänderungen und Identitätsprüfung umgesetzt und evaluiert – inkl. mehrsprachiger Echtzeit‑Szenarien (ASR/Übersetzung). Qualität sichere ich über Conversation‑Evaluation (Intent/Slot, WER, AHT/FCR) mit Canary‑Releases und A/B‑Tests; dazu MLOps mit Drift‑Erkennung, Prompt‑/Modell‑Monitoring, CI/CD und Observability. Sicherheit setze ich by design um (PII‑Redaktion, RBAC, Auditability) und orientiere mich an ISO 27001, SOC 2, PCI, HIPAA und GDPR. Basis sind meine Research‑Rollen (RAG‑Datenbank, ML für Geodaten; Publikationen bei Springer/CEUR) sowie Praktika bei KPMG und der Deutschen Bahn.

Das möchte ich bei Parloa einbringen: kurzfristig ein Monitoring‑MVP und belastbare Guardrails für priorisierte Flows, anschließend ein A/B‑Testing‑Framework und datengetriebene Prompt/Flow‑Iterationen – mit dem Ziel, Transfer‑ und Bearbeitungszeiten zu senken und die Erstlösungsquote zu erhöhen. Ich freue mich auf die Zusammenarbeit mit Engineering, Product und Ops und lerne gern im Team.