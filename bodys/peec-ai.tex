Peec AI’s goal—helping brands become visible in AI search—requires reverse-engineering LLM behavior, extracting reliable signals, and turning them into production features. That end-to-end loop is where I work best. In a Series A, on-site setting I can iterate quickly with engineering, take ownership of models and data pipelines, and help tighten the feedback loop between offline evaluation and live impact.

At KISS, I instrumented OpenAI, Claude, Gemini, Perplexity and Llama to parse citations and response structure, built a RAG datastore, and designed evaluation harnesses to measure retrieval quality and consistency—exactly the signal-to-feature plumbing needed to influence AI search rankings. I’ve turned research into services with Python/SQL, Pandas/NumPy, PyTorch/TensorFlow/HuggingFace, FastAPI, Docker and CI, and I’m comfortable on GCP (BigQuery, Cloud Functions, Firestore, Postgres/AlloyDB). Earlier, at MIR, I worked on geospatial ML for bike‑path detection (Springer 2023) and on VotingAid (CEUR 2025), translating model outputs into actionable recommendations. At KPMG and Deutsche Bahn, I communicated technical trade-offs to non-technical stakeholders. I’d bring the same approach at Peec: instrument AI/search APIs for ranking signals, design robust pipelines, iterate on ranking and recommendation models, and ship monitored endpoints that customers can trust—while staying curious, collaborative, and hands-on in Berlin.