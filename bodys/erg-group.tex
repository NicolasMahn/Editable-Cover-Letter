Your focus on agentic LLMs that reason, plan, and act safely in enterprise environments resonates with the systems I’ve been building. I’m motivated by making autonomous workflows robust and measurable—connecting retrieval, tool-use, and evaluation so agents behave reliably at scale. The chance to help set architecture and best practices alongside a high-caliber team, while keeping latency and availability front and center, is exactly where I want to contribute.

In my current research role, I designed an experimental RAG database and retrieval pipeline (FAISS/pgvector) with hybrid search, metadata filters, and re-ranking, plus rubric-based LLM evaluations and regression tests. I’ve prototyped planner–executor loops, codified tool schemas and safety guardrails, and maintained a failure-mode catalog for RAG. For my M.Sc. thesis, I built an agent for interactive data analysis with retrieval, code-generation tools, and safeguards; I applied PEFT (LoRA/QLoRA) and experimented with quantization to reduce cost and latency. My MLOps practice includes containerized inference, CI/CD, model/version management, and telemetry—habits shaped by work with enterprise stakeholders at KPMG and Deutsche Bahn.

I’d bring a rigorous yet pragmatic approach to agentic workflows, retrieval architecture, and efficient adaptation, while continuing to grow in large-scale finetuning and advanced inference (e.g., vLLM, speculative decoding). I’m eager to mentor, codify patterns, and collaborate on a frontier AI roadmap that ships safe, high-impact agents for Fortune 500 use cases.